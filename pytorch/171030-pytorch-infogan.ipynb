{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_height = 28\n",
    "        self.input_width = 28\n",
    "        self.input_dim = 62 + 12  # 12は何？\n",
    "        self.output_dim = 1\n",
    "    \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),  # TODO: 論文だとReLU => BatchNormになってる。順番変えるとどうなる？\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        initialize_weights(self)\n",
    "    \n",
    "    def forward(self, input, cont_code, dist_code):\n",
    "        x = torch.cat([input, cont_code, dist_code], 1)\n",
    "        print('***', x.size())\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, (self.input_height // 4), (self.input_width // 4))\n",
    "        x = self.deconv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_height = 28\n",
    "        self.input_width = 28\n",
    "        self.input_dim = 1\n",
    "        self.output_dim = 1\n",
    "        self.len_discrete_code = 10   # categorical distribution (label)\n",
    "        self.len_continuous_code = 2  # gaussian distribution (rotation, thickness)\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_height // 4) * (self.input_width // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, self.output_dim + self.len_continuous_code + self.len_discrete_code),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        initialize_weights(self)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_height // 4) * (self.input_width // 4))\n",
    "        x = self.fc(x)\n",
    "        a = F.sigmoid(x[:, self.output_dim])  # for real or fake\n",
    "        b = x[:, self.output_dim:self.output_dim + self.len_continuous_code]  # cont_code\n",
    "        c = x[:, self.output_dim + self.len_continuous_code:]  # disc_code\n",
    "        \n",
    "        return a, b, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(dataset):\n",
    "    data_dir = os.path.join(\"./data\", dataset)\n",
    "\n",
    "    def extract_data(filename, num_data, head_size, data_size):\n",
    "        with gzip.open(filename) as bytestream:\n",
    "            bytestream.read(head_size)\n",
    "            buf = bytestream.read(data_size * num_data)\n",
    "            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n",
    "        return data\n",
    "\n",
    "    data = extract_data(data_dir + '/train-images-idx3-ubyte.gz', 60000, 16, 28 * 28)\n",
    "    trX = data.reshape((60000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    trY = data.reshape((60000))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28 * 28)\n",
    "    teX = data.reshape((10000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "    teY = data.reshape((10000))\n",
    "\n",
    "    trY = np.asarray(trY).astype(np.int)\n",
    "    teY = np.asarray(teY)\n",
    "\n",
    "    X = np.concatenate((trX, teX), axis=0)\n",
    "    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n",
    "\n",
    "    seed = 547\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "\n",
    "    y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y):\n",
    "        y_vec[i, y[i]] = 1\n",
    "\n",
    "    X = X.transpose(0, 3, 1, 2) / 255.\n",
    "    # y_vec = y_vec.transpose(0, 3, 1, 2)\n",
    "\n",
    "    X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "    y_vec = torch.from_numpy(y_vec).type(torch.FloatTensor)\n",
    "    return X, y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class InfoGAN(object):\n",
    "    def __init__(self):\n",
    "        self.epoch = 5\n",
    "        self.batch_size = 64\n",
    "        self.len_discrete_code = 10\n",
    "        self.len_continuous_code = 2\n",
    "        \n",
    "        self.G = generator()\n",
    "        self.D = discriminator()\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        # 2つのparametersのgeneratorを連結している\n",
    "        self.info_optimizer = optim.Adam(itertools.chain(self.G.parameters(), self.D.parameters()), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "        self.CE_loss = nn.CrossEntropyLoss()\n",
    "        self.MSE_loss = nn.MSELoss()\n",
    "\n",
    "        self.data_X, self.data_Y = load_mnist('mnist')\n",
    "        self.z_dim = 62\n",
    "        self.y_dim = 10\n",
    "\n",
    "    def train(self):\n",
    "        self.y_real = Variable(torch.ones(self.batch_size, 1))\n",
    "        self.y_fake = Variable(torch.zeros(self.batch_size, 1))\n",
    "        \n",
    "        self.D.train()\n",
    "        print('training start!')\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()\n",
    "            for iter in range(len(self.data_X) // self.batch_size):\n",
    "                x_ = self.data_X[iter * self.batch_size: (iter + 1) * self.batch_size]\n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                print('x_', x_.size())\n",
    "                print('z_', z_.size())\n",
    "                \n",
    "                # TODO: SUPERVISEDではないパターンも検討する\n",
    "                # disc codeには1-of-Kのラベルを与える\n",
    "                y_disc = self.data_Y[iter * self.batch_size: (iter + 1) * self.batch_size]\n",
    "                # TODO: y_contは何を意味している？\n",
    "                y_cont = torch.from_numpy(np.random.uniform(-1, 1, size=(self.batch_size, 2))).type(torch.FloatTensor)\n",
    "\n",
    "                x_, z_, y_disc, y_cont = Variable(x_), Variable(z_), Variable(y_disc), Variable(y_cont)\n",
    "                \n",
    "                # updte D network\n",
    "                self.D_optimizer.zero_grad()\n",
    "                \n",
    "                # cont_codeとdisc_codeは使わない？？？\n",
    "                D_real, _, _ = self.D(x_)\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real)\n",
    "                print('D_real:', D_real.size())\n",
    "                \n",
    "                G_ = self.G(z_, y_cont, y_disc)  # generatorが生成した画像 (N, 1, 28, 28)\n",
    "                print('y_cont:', y_cont.size())\n",
    "                print('y_disc:', y_disc.size())\n",
    "                print('G_:', G_.size())\n",
    "                D_fake, _, _ = self.D(G_)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake)\n",
    "                \n",
    "                D_loss = D_real_loss + D_fake_loss\n",
    "                D_loss.backward(retain_graph=True)  # TODO: retain_graphは何？\n",
    "                self.D_optimizer.step()\n",
    "                \n",
    "                # update G network\n",
    "                self.G_optimizer.zero_grad()\n",
    "                \n",
    "                G_ = self.G(z_, y_cont, y_disc)\n",
    "                D_fake, D_cont, D_disc = self.D(G_)\n",
    "                print('D_fake:', D_fake.size())\n",
    "                print('D_cont:', D_cont.size())\n",
    "                print('D_disc:', D_disc.size())\n",
    "                \n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real)\n",
    "                G_loss.backward(retain_graph=True)\n",
    "                self.G_optimizer.step()\n",
    "                \n",
    "                # information loss\n",
    "                disc_loss = self.CE_loss(D_disc, torch.max(y_disc, 1)[1])  # ラベルのCrossEntropyLoss\n",
    "                # TODO: D_contを入力のランダムのy_contに近づけようとしている？？？\n",
    "                cont_loss = self.MSE_loss(D_cont, y_cont)\n",
    "                info_loss = disc_loss + cont_loss\n",
    "                print('info_loss:', info_loss.data[0])\n",
    "                info_loss.backward()\n",
    "                self.info_optimizer.step()\n",
    "                break\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start!\n",
      "x_ torch.Size([64, 1, 28, 28])\n",
      "z_ torch.Size([64, 62])\n",
      "D_real: torch.Size([64])\n",
      "*** torch.Size([64, 74])\n",
      "y_cont: torch.Size([64, 2])\n",
      "y_disc: torch.Size([64, 10])\n",
      "G_: torch.Size([64, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koichiro.mori/.pyenv/versions/anaconda3-4.2.0/lib/python3.5/site-packages/torch/nn/functional.py:767: UserWarning: Using a target size (torch.Size([64, 1])) that is different to the input size (torch.Size([64])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** torch.Size([64, 74])\n",
      "D_fake: torch.Size([64])\n",
      "D_cont: torch.Size([64, 2])\n",
      "D_disc: torch.Size([64, 10])\n",
      "info_loss: 2.9132559299468994\n"
     ]
    }
   ],
   "source": [
    "infogan = InfoGAN()\n",
    "infogan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
