{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import gzip\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_weights(net):\n",
    "    for m in net.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.ConvTranspose2d):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.02)\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator (\n",
       "  (fc): Sequential (\n",
       "    (0): Linear (72 -> 1024)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): Linear (1024 -> 6272)\n",
       "    (4): BatchNorm1d(6272, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (5): ReLU ()\n",
       "  )\n",
       "  (deconv): Sequential (\n",
       "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (4): Sigmoid ()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class generator(nn.Module):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        super(generator, self).__init__()\n",
    "        self.input_height = 28\n",
    "        self.input_width = 28\n",
    "        self.input_dim = 62 + 10  # zの次元 + クラスの次元（10クラス）\n",
    "        self.output_dim = 1\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            # 入力の1/4のサイズに縮小\n",
    "            nn.Linear(1024, 128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.BatchNorm1d(128 * (self.input_height // 4) * (self.input_width // 4)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, self.output_dim, 4, 2, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        initialize_weights(self)\n",
    "    \n",
    "    def forward(self, input, label):\n",
    "        x = torch.cat([input, label], 1)\n",
    "        print('***', x.size())\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 128, (self.input_height // 4), (self.input_width // 4))\n",
    "        x = self.deconv(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "gen = generator()\n",
    "gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4825  0.4603 -0.1724\n",
       "-0.7229  1.3024  0.6668\n",
       "[torch.FloatTensor of size 2x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4825  0.4603 -0.1724\n",
       "-0.7229  1.3024  0.6668\n",
       "-0.4825  0.4603 -0.1724\n",
       "-0.7229  1.3024  0.6668\n",
       "-0.4825  0.4603 -0.1724\n",
       "-0.7229  1.3024  0.6668\n",
       "[torch.FloatTensor of size 6x3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x, x), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4825  0.4603 -0.1724 -0.4825  0.4603 -0.1724 -0.4825  0.4603 -0.1724\n",
       "-0.7229  1.3024  0.6668 -0.7229  1.3024  0.6668 -0.7229  1.3024  0.6668\n",
       "[torch.FloatTensor of size 2x9]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x, x, x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "discriminator (\n",
       "  (conv): Sequential (\n",
       "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU (0.2)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (4): LeakyReLU (0.2)\n",
       "  )\n",
       "  (fc1): Sequential (\n",
       "    (0): Linear (6272 -> 1024)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): LeakyReLU (0.2)\n",
       "  )\n",
       "  (dc): Sequential (\n",
       "    (0): Linear (1024 -> 1)\n",
       "    (1): Sigmoid ()\n",
       "  )\n",
       "  (c1): Sequential (\n",
       "    (0): Linear (1024 -> 10)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class discriminator(nn.Module):\n",
    "    def __init__(self, dataset='mnist'):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.input_height = 28\n",
    "        self.input_width = 28\n",
    "        self.input_dim = 1\n",
    "        self.output_dim = 1\n",
    "        self.class_num = 10\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(self.input_dim, 64, 4, 2, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(128 * (self.input_height // 4) * (self.input_width // 4), 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "        self.dc = nn.Sequential(\n",
    "            nn.Linear(1024, self.output_dim),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        self.c1 = nn.Sequential(\n",
    "            nn.Linear(1024, self.class_num),\n",
    "        )\n",
    "        \n",
    "        initialize_weights(self)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = self.conv(input)\n",
    "        x = x.view(-1, 128 * (self.input_height // 4) * (self.input_width // 4))\n",
    "        x = self.fc1(x)\n",
    "        d = self.dc(x)\n",
    "        c = self.c1(x)\n",
    "        \n",
    "        return d, c\n",
    "\n",
    "disc = discriminator()\n",
    "disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist(dataset):\n",
    "    data_dir = os.path.join(\"./data\", dataset)\n",
    "\n",
    "    def extract_data(filename, num_data, head_size, data_size):\n",
    "        with gzip.open(filename) as bytestream:\n",
    "            bytestream.read(head_size)\n",
    "            buf = bytestream.read(data_size * num_data)\n",
    "            data = np.frombuffer(buf, dtype=np.uint8).astype(np.float)\n",
    "        return data\n",
    "\n",
    "    data = extract_data(data_dir + '/train-images-idx3-ubyte.gz', 60000, 16, 28 * 28)\n",
    "    trX = data.reshape((60000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/train-labels-idx1-ubyte.gz', 60000, 8, 1)\n",
    "    trY = data.reshape((60000))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-images-idx3-ubyte.gz', 10000, 16, 28 * 28)\n",
    "    teX = data.reshape((10000, 28, 28, 1))\n",
    "\n",
    "    data = extract_data(data_dir + '/t10k-labels-idx1-ubyte.gz', 10000, 8, 1)\n",
    "    teY = data.reshape((10000))\n",
    "\n",
    "    trY = np.asarray(trY).astype(np.int)\n",
    "    teY = np.asarray(teY)\n",
    "\n",
    "    X = np.concatenate((trX, teX), axis=0)\n",
    "    y = np.concatenate((trY, teY), axis=0).astype(np.int)\n",
    "\n",
    "    seed = 547\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(X)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(y)\n",
    "\n",
    "    y_vec = np.zeros((len(y), 10), dtype=np.float)\n",
    "    for i, label in enumerate(y):\n",
    "        y_vec[i, y[i]] = 1\n",
    "\n",
    "    X = X.transpose(0, 3, 1, 2) / 255.\n",
    "    # y_vec = y_vec.transpose(0, 3, 1, 2)\n",
    "\n",
    "    X = torch.from_numpy(X).type(torch.FloatTensor)\n",
    "    y_vec = torch.from_numpy(y_vec).type(torch.FloatTensor)\n",
    "    return X, y_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([70000, 1, 28, 28]) torch.Size([70000, 10])\n",
      "torch.Size([64, 1]) torch.Size([64, 1])\n",
      "training start!!\n",
      "*** torch.Size([64, 72])\n",
      "*** torch.Size([64, 72])\n",
      "5.925044059753418 2.528146505355835\n"
     ]
    }
   ],
   "source": [
    "class ACGAN(object):\n",
    "    def __init__(self):\n",
    "        self.epoch = 5\n",
    "        self.sample_num = 100\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.G = generator()\n",
    "        self.D = discriminator()\n",
    "        self.G_optimizer = optim.Adam(self.G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.D_optimizer = optim.Adam(self.D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.BCE_loss = nn.BCELoss()\n",
    "        self.CE_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.data_X, self.data_Y = load_mnist('mnist')\n",
    "        self.z_dim = 62\n",
    "        self.y_dim = 10\n",
    "        print(self.data_X.shape, self.data_Y.shape)\n",
    "\n",
    "    def train(self):\n",
    "        self.y_real_ = Variable(torch.ones(self.batch_size, 1))\n",
    "        self.y_fake_ = Variable(torch.zeros(self.batch_size, 1))\n",
    "        print(self.y_real_.size(), self.y_fake_.size())\n",
    "\n",
    "        self.D.train()\n",
    "        print('training start!!')\n",
    "        for epoch in range(self.epoch):\n",
    "            self.G.train()\n",
    "            for iter in range(len(self.data_X) // self.batch_size):\n",
    "                x_ = self.data_X[iter * self.batch_size: (iter + 1) * self.batch_size]\n",
    "                z_ = torch.rand((self.batch_size, self.z_dim))\n",
    "                y_vec_ = self.data_Y[iter * self.batch_size: (iter + 1) * self.batch_size]\n",
    "                \n",
    "                x_, z_, y_vec_ = Variable(x_), Variable(z_), Variable(y_vec_)\n",
    "                \n",
    "                # update D network\n",
    "                self.D_optimizer.zero_grad()\n",
    "                D_real, C_real = self.D(x_)  # 本物のデータを入力\n",
    "                D_real_loss = self.BCE_loss(D_real, self.y_real_)\n",
    "                C_real_loss = self.CE_loss(C_real, torch.max(y_vec_, 1)[1])\n",
    "                \n",
    "                G_ = self.G(z_, y_vec_)\n",
    "                D_fake, C_fake = self.D(G_)\n",
    "                D_fake_loss = self.BCE_loss(D_fake, self.y_fake_)\n",
    "                C_fake_loss = self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n",
    "                \n",
    "                D_loss = D_real_loss + C_real_loss + D_fake_loss + C_fake_loss\n",
    "                D_loss.backward()\n",
    "                self.D_optimizer.step()\n",
    "                \n",
    "                # update G network\n",
    "                self.G_optimizer.zero_grad()\n",
    "                G_ = self.G(z_, y_vec_)\n",
    "                D_fake, C_fake = self.D(G_)\n",
    "                \n",
    "                G_loss = self.BCE_loss(D_fake, self.y_real_)\n",
    "                C_fake_loss = self.CE_loss(C_fake, torch.max(y_vec_, 1)[1])\n",
    "                \n",
    "                G_loss += C_fake_loss\n",
    "                G_loss.backward()\n",
    "                self.G_optimizer.step()\n",
    "\n",
    "                print(D_loss.data[0], G_loss.data[0])\n",
    "                break\n",
    "            break\n",
    "\n",
    "acgan = ACGAN()\n",
    "acgan.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
