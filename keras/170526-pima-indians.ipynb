{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ランダムシードは固定するべし\n",
    "# 結果を再現・アルゴリズムを比較するため\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-05-26 17:02:49--  http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\n",
      "Resolving archive.ics.uci.edu... 128.195.10.249\n",
      "Connecting to archive.ics.uci.edu|128.195.10.249|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23279 (23K) [text/plain]\n",
      "Saving to: ‘pima-indians-diabetes.data.2’\n",
      "\n",
      "pima-indians-diabet 100%[===================>]  22.73K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2017-05-26 17:02:49 (174 KB/s) - ‘pima-indians-diabetes.data.2’ saved [23279/23279]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('pima-indians-diabetes.data', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,    0.627,   50.   ,    1.   ],\n",
       "       [   1.   ,   85.   ,   66.   , ...,    0.351,   31.   ,    0.   ],\n",
       "       [   8.   ,  183.   ,   64.   , ...,    0.672,   32.   ,    1.   ],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,    0.245,   30.   ,    0.   ],\n",
       "       [   1.   ,  126.   ,   60.   , ...,    0.349,   47.   ,    1.   ],\n",
       "       [   1.   ,   93.   ,   70.   , ...,    0.315,   23.   ,    0.   ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n",
      "[ -7.74843153e-17   3.61400724e-18  -1.32724416e-17   7.76288755e-17\n",
      "  -5.49329101e-17   2.97273780e-15   1.92438658e-15   2.19297959e-16]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "X_scaled = preprocessing.scale(X)\n",
    "print(X_scaled.shape)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print(X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s - loss: 0.6448 - acc: 0.6719     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.5721 - acc: 0.7253     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.5276 - acc: 0.7500     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.5052 - acc: 0.7526     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.4934 - acc: 0.7461     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.4866 - acc: 0.7552     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.4821 - acc: 0.7630     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.4775 - acc: 0.7604     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.4754 - acc: 0.7643     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.4721 - acc: 0.7682     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.4700 - acc: 0.7695     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.4676 - acc: 0.7669     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.4667 - acc: 0.7682     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.4643 - acc: 0.7682     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.4631 - acc: 0.7682     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.4615 - acc: 0.7656     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.4607 - acc: 0.7747     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.4604 - acc: 0.7786     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.4576 - acc: 0.7773     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.4566 - acc: 0.7812     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.4553 - acc: 0.7826     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.4549 - acc: 0.7773     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.4531 - acc: 0.7839     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.4528 - acc: 0.7826     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.4515 - acc: 0.7839     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.4515 - acc: 0.7839     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.4502 - acc: 0.7852     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.4489 - acc: 0.7891     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.4484 - acc: 0.7878     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.4474 - acc: 0.7852     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.4466 - acc: 0.7891     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.4460 - acc: 0.7865     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.4450 - acc: 0.7865     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.4437 - acc: 0.7852     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.4428 - acc: 0.7891     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.4421 - acc: 0.7878     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.4415 - acc: 0.7826     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.4411 - acc: 0.7865     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.4403 - acc: 0.7891     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.4399 - acc: 0.7878     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.4392 - acc: 0.7930     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.4386 - acc: 0.7878     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.4381 - acc: 0.7930     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.4374 - acc: 0.7930     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.4375 - acc: 0.7904     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.4364 - acc: 0.7904     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.4352 - acc: 0.7969     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.4343 - acc: 0.7943     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.4345 - acc: 0.7969     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.4335 - acc: 0.7943     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.4331 - acc: 0.7982     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.4330 - acc: 0.7969     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.4326 - acc: 0.7891     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.4318 - acc: 0.7904     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.4316 - acc: 0.7995     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.4313 - acc: 0.7943     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.4312 - acc: 0.7917     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.4304 - acc: 0.7995     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.4296 - acc: 0.7995     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.4295 - acc: 0.8021     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.4289 - acc: 0.7995     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.4290 - acc: 0.7943     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.4296 - acc: 0.8008     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.4279 - acc: 0.7917     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.4279 - acc: 0.7982     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.4276 - acc: 0.7982     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.4270 - acc: 0.7969     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.4269 - acc: 0.7982     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.4260 - acc: 0.7982     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.4257 - acc: 0.7956     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.4254 - acc: 0.8021     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.4264 - acc: 0.7982     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.4259 - acc: 0.7969     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.4247 - acc: 0.8060     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.4258 - acc: 0.7995     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.4246 - acc: 0.7995     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.4248 - acc: 0.7956     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.4240 - acc: 0.8047     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.4235 - acc: 0.7969     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.4232 - acc: 0.7995     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.4234 - acc: 0.7982     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.4238 - acc: 0.8021     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.4227 - acc: 0.7969     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.4222 - acc: 0.8008     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.4218 - acc: 0.7995     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.4220 - acc: 0.7956     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.4215 - acc: 0.7969     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.4214 - acc: 0.7982     \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s - loss: 0.4212 - acc: 0.8008     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.4213 - acc: 0.7995     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.4203 - acc: 0.7969     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.4197 - acc: 0.7943     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.4210 - acc: 0.8021     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.4200 - acc: 0.7969     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.4192 - acc: 0.8008     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.4196 - acc: 0.7982     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.4189 - acc: 0.7969     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.4182 - acc: 0.7995     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.4176 - acc: 0.7982     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.4173 - acc: 0.8021     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.4171 - acc: 0.7969     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.4171 - acc: 0.8021     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.4170 - acc: 0.7995     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.4155 - acc: 0.8060     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.4161 - acc: 0.8008     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.4160 - acc: 0.8047     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.4150 - acc: 0.8021     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.4152 - acc: 0.8034     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.4147 - acc: 0.8021     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.4140 - acc: 0.8021     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.4137 - acc: 0.8034     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.4143 - acc: 0.8008     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.4130 - acc: 0.8008     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.4125 - acc: 0.7995     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.4129 - acc: 0.8021     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.4117 - acc: 0.8008     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.4120 - acc: 0.7956     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.4112 - acc: 0.7969     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.4108 - acc: 0.8034     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.4103 - acc: 0.7995     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.4110 - acc: 0.8021     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.4107 - acc: 0.7943     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.4095 - acc: 0.8060     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.4086 - acc: 0.7982     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.4102 - acc: 0.8073     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.4079 - acc: 0.8034     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.4082 - acc: 0.8047     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.4078 - acc: 0.7995     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.4080 - acc: 0.8034     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.4065 - acc: 0.8034     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.4062 - acc: 0.8021     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.4064 - acc: 0.8073     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.4059 - acc: 0.8021     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.4061 - acc: 0.8008     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.4048 - acc: 0.8047     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.4051 - acc: 0.8034     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.4043 - acc: 0.7995     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.4034 - acc: 0.8086     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.4038 - acc: 0.8060     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.4040 - acc: 0.8034     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.4040 - acc: 0.8073     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.4029 - acc: 0.8086     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.4028 - acc: 0.8099     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.4042 - acc: 0.8099     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.4018 - acc: 0.8099     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.4018 - acc: 0.8112     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.4018 - acc: 0.8060     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.4020 - acc: 0.8125     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.4009 - acc: 0.8086     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.4002 - acc: 0.8151     \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_scaled, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 32/768 [>.............................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_scaled, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 83.72%\n"
     ]
    }
   ],
   "source": [
    "print('%s: %.2f%%' % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rounded = [round(x[0]) for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]\n",
      "[ 1.  0.  1.  0.  1.  0.  1.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(rounded[:10])\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "inputs = Input(shape=(8, ))\n",
    "x = Dense(12, activation='relu')(inputs)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s - loss: 0.4722 - acc: 0.7799     \n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s - loss: 0.4649 - acc: 0.7826     \n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s - loss: 0.4604 - acc: 0.7852     \n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s - loss: 0.4575 - acc: 0.7839     \n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s - loss: 0.4551 - acc: 0.7865     \n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s - loss: 0.4518 - acc: 0.7852     \n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s - loss: 0.4497 - acc: 0.7839     \n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s - loss: 0.4485 - acc: 0.7799     \n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s - loss: 0.4467 - acc: 0.7812     \n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s - loss: 0.4451 - acc: 0.7786     \n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s - loss: 0.4432 - acc: 0.7839     \n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s - loss: 0.4423 - acc: 0.7852     \n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s - loss: 0.4405 - acc: 0.7865     \n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s - loss: 0.4393 - acc: 0.7852     \n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s - loss: 0.4386 - acc: 0.7891     \n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s - loss: 0.4375 - acc: 0.7930     \n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s - loss: 0.4372 - acc: 0.7865     \n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s - loss: 0.4351 - acc: 0.7930     \n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s - loss: 0.4341 - acc: 0.7917     \n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s - loss: 0.4333 - acc: 0.7917     \n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s - loss: 0.4319 - acc: 0.7930     \n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s - loss: 0.4311 - acc: 0.7956     \n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s - loss: 0.4306 - acc: 0.7917     \n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s - loss: 0.4304 - acc: 0.7943     \n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s - loss: 0.4286 - acc: 0.7956     \n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s - loss: 0.4283 - acc: 0.7995     \n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s - loss: 0.4273 - acc: 0.7943     \n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s - loss: 0.4267 - acc: 0.7969     \n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s - loss: 0.4256 - acc: 0.7969     \n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s - loss: 0.4249 - acc: 0.7956     \n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s - loss: 0.4239 - acc: 0.7956     \n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s - loss: 0.4239 - acc: 0.8021     \n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s - loss: 0.4218 - acc: 0.8008     \n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s - loss: 0.4211 - acc: 0.7969     \n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s - loss: 0.4203 - acc: 0.7969     \n",
      "Epoch 36/150\n",
      "768/768 [==============================] - 0s - loss: 0.4194 - acc: 0.7982     \n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s - loss: 0.4188 - acc: 0.7995     \n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s - loss: 0.4186 - acc: 0.8047     \n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s - loss: 0.4188 - acc: 0.8047     \n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s - loss: 0.4173 - acc: 0.8021     \n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s - loss: 0.4165 - acc: 0.8060     \n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s - loss: 0.4156 - acc: 0.8060     \n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s - loss: 0.4151 - acc: 0.8047     \n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s - loss: 0.4148 - acc: 0.8034     \n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s - loss: 0.4145 - acc: 0.8060     \n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s - loss: 0.4136 - acc: 0.8086     \n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s - loss: 0.4131 - acc: 0.8125     \n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s - loss: 0.4124 - acc: 0.8099     \n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s - loss: 0.4123 - acc: 0.8099     \n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s - loss: 0.4112 - acc: 0.8060     \n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s - loss: 0.4108 - acc: 0.8125     \n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s - loss: 0.4112 - acc: 0.8138     \n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s - loss: 0.4101 - acc: 0.8151     \n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s - loss: 0.4105 - acc: 0.8086     \n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s - loss: 0.4086 - acc: 0.8138     \n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s - loss: 0.4099 - acc: 0.8112     \n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s - loss: 0.4080 - acc: 0.8125     \n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s - loss: 0.4073 - acc: 0.8177     \n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s - loss: 0.4069 - acc: 0.8164     \n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s - loss: 0.4066 - acc: 0.8099     \n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s - loss: 0.4072 - acc: 0.8099     \n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s - loss: 0.4064 - acc: 0.8125     \n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s - loss: 0.4054 - acc: 0.8125     \n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s - loss: 0.4055 - acc: 0.8164     \n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s - loss: 0.4048 - acc: 0.8125     \n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s - loss: 0.4039 - acc: 0.8151     \n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s - loss: 0.4044 - acc: 0.8151     \n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s - loss: 0.4039 - acc: 0.8164     \n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s - loss: 0.4039 - acc: 0.8203     \n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s - loss: 0.4023 - acc: 0.8190     \n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s - loss: 0.4022 - acc: 0.8164     \n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s - loss: 0.4018 - acc: 0.8151     \n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s - loss: 0.4021 - acc: 0.8151     \n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s - loss: 0.4016 - acc: 0.8177     \n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s - loss: 0.4017 - acc: 0.8151     \n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s - loss: 0.4005 - acc: 0.8112     \n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s - loss: 0.3997 - acc: 0.8203     \n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s - loss: 0.3994 - acc: 0.8177     \n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s - loss: 0.4003 - acc: 0.8190     \n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s - loss: 0.3986 - acc: 0.8177     \n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s - loss: 0.3987 - acc: 0.8190     \n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s - loss: 0.3982 - acc: 0.8164     \n",
      "Epoch 83/150\n",
      "768/768 [==============================] - 0s - loss: 0.3998 - acc: 0.8164     \n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s - loss: 0.3980 - acc: 0.8177     \n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s - loss: 0.3978 - acc: 0.8164     \n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s - loss: 0.3962 - acc: 0.8190     \n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s - loss: 0.3964 - acc: 0.8203     \n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s - loss: 0.3960 - acc: 0.8099     \n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s - loss: 0.3962 - acc: 0.8216     \n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s - loss: 0.3947 - acc: 0.8151     \n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s - loss: 0.3950 - acc: 0.8177     \n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s - loss: 0.3962 - acc: 0.8177     \n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s - loss: 0.3939 - acc: 0.8216     \n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s - loss: 0.3932 - acc: 0.8190     \n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s - loss: 0.3922 - acc: 0.8190     \n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s - loss: 0.3920 - acc: 0.8177     \n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s - loss: 0.3922 - acc: 0.8164     \n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s - loss: 0.3921 - acc: 0.8177     \n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s - loss: 0.3907 - acc: 0.8190     \n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s - loss: 0.3916 - acc: 0.8190     \n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s - loss: 0.3900 - acc: 0.8203     \n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s - loss: 0.3896 - acc: 0.8177     \n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s - loss: 0.3899 - acc: 0.8177     \n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s - loss: 0.3883 - acc: 0.8229     \n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s - loss: 0.3876 - acc: 0.8216     \n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s - loss: 0.3877 - acc: 0.8203     \n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s - loss: 0.3872 - acc: 0.8229     \n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s - loss: 0.3872 - acc: 0.8190     \n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s - loss: 0.3862 - acc: 0.8190     \n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s - loss: 0.3872 - acc: 0.8177     \n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s - loss: 0.3866 - acc: 0.8216     \n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s - loss: 0.3845 - acc: 0.8190     \n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s - loss: 0.3831 - acc: 0.8216     \n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s - loss: 0.3848 - acc: 0.8216     \n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s - loss: 0.3839 - acc: 0.8255     \n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s - loss: 0.3838 - acc: 0.8216     \n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s - loss: 0.3834 - acc: 0.8203     \n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s - loss: 0.3814 - acc: 0.8216     \n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s - loss: 0.3825 - acc: 0.8216     \n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s - loss: 0.3825 - acc: 0.8216     \n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s - loss: 0.3818 - acc: 0.8216     \n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s - loss: 0.3814 - acc: 0.8203     \n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s - loss: 0.3804 - acc: 0.8216     \n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s - loss: 0.3798 - acc: 0.8203     \n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s - loss: 0.3799 - acc: 0.8164     \n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s - loss: 0.3799 - acc: 0.8190     \n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s - loss: 0.3798 - acc: 0.8242     \n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s - loss: 0.3789 - acc: 0.8268     \n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s - loss: 0.3789 - acc: 0.8268     \n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s - loss: 0.3778 - acc: 0.8255     \n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s - loss: 0.3770 - acc: 0.8216     \n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s - loss: 0.3778 - acc: 0.8242     \n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s - loss: 0.3767 - acc: 0.8268     \n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s - loss: 0.3781 - acc: 0.8294     \n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s - loss: 0.3770 - acc: 0.8255     \n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s - loss: 0.3758 - acc: 0.8242     \n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s - loss: 0.3755 - acc: 0.8268     \n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s - loss: 0.3748 - acc: 0.8281     \n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s - loss: 0.3742 - acc: 0.8255     \n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s - loss: 0.3740 - acc: 0.8320     \n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s - loss: 0.3738 - acc: 0.8229     \n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s - loss: 0.3746 - acc: 0.8294     \n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s - loss: 0.3725 - acc: 0.8320     \n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s - loss: 0.3724 - acc: 0.8307     \n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s - loss: 0.3717 - acc: 0.8359     \n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s - loss: 0.3728 - acc: 0.8320     \n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s - loss: 0.3716 - acc: 0.8333     \n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s - loss: 0.3719 - acc: 0.8268     \n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s - loss: 0.3715 - acc: 0.8320     \n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s - loss: 0.3712 - acc: 0.8294     \n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_scaled, Y, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_88 (Dense)             (None, 12)                108       \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.optimizers.SGD at 0x137fc0198>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
